{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from pyvi import ViTokenizer,ViPosTagger\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import text, sequence \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_LEN = 20\n",
    "TRUNC_TYPE = 'post'\n",
    "PADDING_TYPE = 'post'\n",
    "OOV_TOKEN = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv') # for training\n",
    "test_data = pd.read_csv('../data/test.csv') # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokenizer and word_index\n",
    "sentence_tokenizer = text.Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
    "sentence_tokenizer.fit_on_texts(train_data.sentence.values)\n",
    "word_index = sentence_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentence\n",
    "train_sentence = sentence_tokenizer.texts_to_sequences(train_data.sentence.values) # Convert all word to sequence\n",
    "train_sentence = sequence.pad_sequences(train_sentence, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating=TRUNC_TYPE) # Pad each entry\n",
    "test_sentence = sentence_tokenizer.texts_to_sequences(test_data.sentence.values) # Convert all word to sequence\n",
    "test_sentence = sequence.pad_sequences(test_sentence, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating=TRUNC_TYPE) # Pad each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize emotion\n",
    "train_emotion = pd.get_dummies(train_data.emotion.values)\n",
    "test_emotion = pd.get_dummies(test_data.emotion.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 20, 64)            320000    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 256)               197632    \n_________________________________________________________________\ndense (Dense)                (None, 7)                 1799      \n=================================================================\nTotal params: 519,431\nTrainable params: 519,431\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    layers.Bidirectional(layers.LSTM(128, dropout=.5, recurrent_dropout=.5)),\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    # layers.Dropout(.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4993 samples, validate on 555 samples\nEpoch 1/10\n4992/4993 [============================>.] - ETA: 0s - loss: 1.7972 - accuracy: 0.2736\nEpoch 00001: val_accuracy improved from -inf to 0.31171, saving model to LSTMV1.h5\n4993/4993 [==============================] - 26s 5ms/sample - loss: 1.7972 - accuracy: 0.2738 - val_loss: 1.7261 - val_accuracy: 0.3117\nEpoch 2/10\n4992/4993 [============================>.] - ETA: 0s - loss: 1.6363 - accuracy: 0.3425\nEpoch 00002: val_accuracy improved from 0.31171 to 0.41441, saving model to LSTMV1.h5\n4993/4993 [==============================] - 16s 3ms/sample - loss: 1.6365 - accuracy: 0.3425 - val_loss: 1.5301 - val_accuracy: 0.4144\nEpoch 3/10\n4992/4993 [============================>.] - ETA: 0s - loss: 1.4089 - accuracy: 0.4523\nEpoch 00003: val_accuracy improved from 0.41441 to 0.46486, saving model to LSTMV1.h5\n4993/4993 [==============================] - 13s 3ms/sample - loss: 1.4087 - accuracy: 0.4524 - val_loss: 1.4262 - val_accuracy: 0.4649\nEpoch 4/10\n4992/4993 [============================>.] - ETA: 0s - loss: 1.2073 - accuracy: 0.5535\nEpoch 00004: val_accuracy improved from 0.46486 to 0.50450, saving model to LSTMV1.h5\n4993/4993 [==============================] - 16s 3ms/sample - loss: 1.2073 - accuracy: 0.5534 - val_loss: 1.3683 - val_accuracy: 0.5045\nEpoch 5/10\n4992/4993 [============================>.] - ETA: 0s - loss: 1.0711 - accuracy: 0.6210\nEpoch 00005: val_accuracy improved from 0.50450 to 0.51892, saving model to LSTMV1.h5\n4993/4993 [==============================] - 15s 3ms/sample - loss: 1.0711 - accuracy: 0.6211 - val_loss: 1.3803 - val_accuracy: 0.5189\nEpoch 6/10\n4992/4993 [============================>.] - ETA: 0s - loss: 0.9492 - accuracy: 0.6645\nEpoch 00006: val_accuracy improved from 0.51892 to 0.52613, saving model to LSTMV1.h5\n4993/4993 [==============================] - 14s 3ms/sample - loss: 0.9493 - accuracy: 0.6643 - val_loss: 1.4203 - val_accuracy: 0.5261\nEpoch 7/10\n4992/4993 [============================>.] - ETA: 0s - loss: 0.8601 - accuracy: 0.6987\nEpoch 00007: val_accuracy improved from 0.52613 to 0.54955, saving model to LSTMV1.h5\n4993/4993 [==============================] - 15s 3ms/sample - loss: 0.8600 - accuracy: 0.6988 - val_loss: 1.4243 - val_accuracy: 0.5495\nEpoch 00007: early stopping\n"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "initial_epochs = 10\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n",
    "mc=ModelCheckpoint('LSTMV1.h5', monitor='val_accuracy', mode='max', save_best_only=True,verbose=1) \n",
    "history = model.fit(train_sentence, train_emotion,batch_size=64, epochs=initial_epochs, validation_split=.1, verbose=1, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "693/693 [==============================] - 0s 643us/sample - loss: 1.4264 - accuracy: 0.5281\n0.5281385\n"
    }
   ],
   "source": [
    "model.load_weights('LSTMV1.h5')\n",
    "result = model.evaluate(test_sentence, test_emotion)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.2622929  0.65266967 0.00516923 0.02511064 0.033725   0.00861775\n  0.01241482]]\nDisgust\n"
    }
   ],
   "source": [
    "sentence = 'thật là kinh tởm'\n",
    "labels = ['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Surprise']\n",
    "# labels = ['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Sadness', 'Surprise']\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "sentence = sentence_tokenizer.texts_to_sequences([sentence])\n",
    "sentence = sequence.pad_sequences(sentence, maxlen=MAX_LEN, padding=PADDING_TYPE, truncating=TRUNC_TYPE)\n",
    "pred = model.predict([sentence])\n",
    "print(pred) \n",
    "print(labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}